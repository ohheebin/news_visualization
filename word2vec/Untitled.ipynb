{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordgram_analyze(contents):\n",
    "    wordgram_dictionary = OrderedDict()\n",
    "    \n",
    "    i = 0 \n",
    "    \n",
    "    while i < len(contents):\n",
    "        word = \"\"\n",
    "        jmp_count = 1\n",
    "        for j in range(1, len(contents)-i):\n",
    "            if contents[i+j] == ' ' or contents[i+j] == '\\r' or contents[i+j] == '\\n':\n",
    "                jmp_count = j\n",
    "                break\n",
    "            else:\n",
    "                word += contents[i+j]\n",
    "        if len(word) < 1:\n",
    "            i += jmp_count\n",
    "            continue\n",
    "        if word in wordgram_dictionary:\n",
    "            wordgram_dictionary[word] += 1\n",
    "        else:\n",
    "            wordgram_dictionary[word] = 1\n",
    "        i += jmp_count\n",
    "    \n",
    "    return wordgram_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_value(dictionary, word):\n",
    "    \n",
    "    return dictionary[word] / len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_analyze(path):\n",
    "    \n",
    "    text = fileio.read_file(path)\n",
    "    dictionaty = wordgram_analyze(text)\n",
    "    tf_dict = OrderedDict()\n",
    "    for k, v in dictionaty.items():\n",
    "        tf_dict[str(k)] = tf_value(dictionary, str(k))\n",
    "    sorted_tf_dict = OrderedDict(sorted(tf_dict.items(), len=_operator.itemgetter(1), reverse=True))\n",
    "    return sorted_tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordgram_map(dirpath):\n",
    "    \n",
    "    file_list = listdir(dirpath)\n",
    "    dict_map = []\n",
    "    for file in file_list:\n",
    "        extension = os.path.splitext(file)[1]\n",
    "        if extension != '.txt':\n",
    "            continue\n",
    "        file = dirpath + file\n",
    "        file_contents = fileio.read_file(file)\n",
    "        file_dict = wordgram_analyze(file_contents)\n",
    "        fict_map.append(file_dict)\n",
    "    return dict_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf_value(dirpath, dict_map, word):\n",
    "    file_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
