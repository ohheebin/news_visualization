#tfidf를 구하기 위해서 tf와 idf를 구하기 위한 시작 1글자 이상의 단어만
def get_tags(text):
    spliter = Twitter()
    nouns = spliter.nouns(text)
    count = Counter(nouns)
    return_list = []
    for n, c in count.most_common():
        if len(n) > 1:
            temp = {'tag': n, 'count': c, 'dict_count' : 1}
            return_list.append(temp)
    return return_list
    
#tfidf가 0에 가까울 수록 좋지 제거 대상
#파라미터로는 각각의 단어에 대한 단어의 총 count와 어떤 문서에 쓰여져있는지의 count를 저장한 dict를 가져오고 총 문서의 수인 dict_num을 가져온다.
#많은 문서에서 쓰이는 단어 일수록 idf 값이 0에 가까워 지며 그로 인해 tf-idf 값이 0에 가까워 지면 제거 대상이다.
#로그빈도를 이용해서 tf값을 구했다. 값이 커지는 것을 막을 수 있다.
def tfidf_func(result_dict, dict_num):
    result = []
    for tag in result_dict:
        tf = math.log10(result_dict[tag][0] + 1)
        idf = math.log10(dict_num / result_dict[tag][1])
        tfidf = tf * idf
        #tfidf 값을 조절해서 자주쓰이는 단어에 대해 알아낼수 있다.
        if tfidf < 1.9 and result_dict[tag][0] > 10:
            result.append(tag)
    return result
    
#tfidf 하기
def result_tfidf():
    num = 0
    #전체 문서에 쓰인 명사와 그 명사의 count, 명사의 문서에 쓰인 count 수를 저장하기 위한 변수
    result_dict = {}
    output_file_name = 'noun.txt'
    for (path, dir , files) in os.walk("article_dict"):
        #존재 여부 확인
        for fname in dir:
            fullname = path+"/"+fname
            for file in os.listdir(fullname):
                if file.endswith(".txt"):
                    open_text_file = open(fullname+"/"+file, 'r')
                    text = open_text_file.read()
            
                    #get_tags(text)를 통해 하나의 문서에 쓰인 명사와 그 명사의 count수 그리고 문서 count수인 1을 return 받는다.
                    tags = get_tags(text)
                    open_text_file.close()
            
                    #전체적인 명사와 count, dict_count를 저장해 result_dict에 그 값들을 저장한다. 
                    for tag in tags:
                        noun = tag['tag']
                        count = tag['count']
                        dict_count = tag['dict_count']
                        
                        open_output_file = open(output_file_name, 'a+')
                        open_output_file.write(noun+'\n')
                        open_output_file.close()
                        
                        if noun in result_dict:
                            result_dict[noun][0] += count
                            result_dict[noun][1] += dict_count
                        else:
                            result_dict[noun] = [count, dict_count]
                    
                    #총 문서의 수를 저장하기 위해 사용하는 변수 하나의 문서를 처리할떄 마다 값을 1증가 시킨다.        
                    num = num + 1
    #위에서 계산한 result_dict와 전체 문서의 수인 num값을 파라미터로 넘겨준다.        
    return tfidf_func(result_dict, num)